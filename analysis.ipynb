{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(txt):\n",
    "    cleanText = re.sub('http\\S+\\s', ' ', txt)\n",
    "    #http-only select it,http\\S-select http+next one cherecter, http\\S+ -means full address,\\s-next space.\n",
    "    cleanText = re.sub('RT|cc', ' ', cleanText)\n",
    "    #These are often used in tweets and are common in text data from social media.\n",
    "    cleanText = re.sub('#\\S+\\s', ' ', cleanText)\n",
    "    cleanText = re.sub('@\\S+', '  ', cleanText)\n",
    "    cleanText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', cleanText)\n",
    "    #This line removes special characters such as punctuation, excluding whitespaces\n",
    "    cleanText = re.sub(r'[^\\x00-\\x7f]', ' ', cleanText)\n",
    "    #This line removes non-ASCII characters\n",
    "    cleanText = re.sub('\\s+', ' ', cleanText)\n",
    "    #This line substitutes sequences of whitespace characters with a single whitespace character.\n",
    "    #This ensures that multiple consecutive whitespace characters are reduced to just one.\n",
    "    return cleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi how are you Today is the first day of the week \n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hi, how are you? Today is the first day of the week.\"\n",
    "user_input = clean_text(input_text)\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (4.40.2)\n",
      "Requirement already satisfied: filelock in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (2024.5.10)\n",
      "Requirement already satisfied: requests in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi how are you Today is the first day of the week \n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hi, how are you? Today is the first day of the week.\"\n",
    "user_input = clean_text(input_text)\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\DATA SCIENCE-25\\Generative AI\\generation_app\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "g:\\DATA SCIENCE-25\\Generative AI\\generation_app\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) positive 0.9687\n",
      "2) neutral 0.0249\n",
      "3) negative 0.0064\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "#model.save_pretrained(MODEL)\n",
    "text = \"I love you very much\"\n",
    "text = clean_text(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\DATA SCIENCE-25\\Generative AI\\generation_app\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Comments:\n",
      "Friendly:\n",
      "That's fantastic! Hi how are you Today is the first day of the week Â of being a vegetarian for your own personal reasons! We've decided to start off by taking a look at three of your favourite ways to feed your animals.\n",
      "\n",
      "Funny:\n",
      "You won't believe it, but Hi how are you Today is the first day of the week Â for us, a new start for you. Thank You very much for taking the time to speak with us today. It's a great day,\n",
      "\n",
      "Congratulating:\n",
      "Congratulations on Hi how are you Today is the first day of the week Â from all of you.\n",
      "Hi. A short recap with the first day of the week and the start of a month, now that you have all been invited we need\n",
      "\n",
      "Questioning:\n",
      "I'm curious, Hi how are you Today is the first day of the week \"\n",
      "\n",
      "\"Hello and welcome, we live in a small county in south eastern England. I'm on your mobile so don't be rude please come in today\n",
      "\n",
      "Disagreement:\n",
      "Sorry, I have to disagree. Hi how are you Today is the first day of the week Â of theÂ concert! As is so frequently the case at the symposium and the workshop the day that is for other people, one of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the text generation pipeline with GPT-2 model\n",
    "text_generator = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\n",
    "\n",
    "# Define functions to generate prompts for different types of comments\n",
    "def generate_friendly_prompt(input_sentence):\n",
    "    return f\"That's fantastic! {input_sentence}\"\n",
    "\n",
    "def generate_funny_prompt(input_sentence):\n",
    "    return f\"You won't believe it, but {input_sentence}\"\n",
    "\n",
    "def generate_congratulating_prompt(input_sentence):\n",
    "    return f\"Congratulations on {input_sentence}\"\n",
    "\n",
    "def generate_questioning_prompt(input_sentence):\n",
    "    return f\"I'm curious, {input_sentence}\"\n",
    "\n",
    "def generate_disagreement_prompt(input_sentence):\n",
    "    return f\"Sorry, I have to disagree. {input_sentence}\"\n",
    "\n",
    "# Get user input sentence\n",
    "#user_sentence = input(\"Enter your sentence: \")\n",
    "\n",
    "# Define prompts for different types of comments\n",
    "prompts = {\n",
    "    \"Friendly\": generate_friendly_prompt(user_input),\n",
    "    \"Funny\": generate_funny_prompt(user_input),\n",
    "    \"Congratulating\": generate_congratulating_prompt(user_input),\n",
    "    \"Questioning\": generate_questioning_prompt(user_input),\n",
    "    \"Disagreement\": generate_disagreement_prompt(user_input)\n",
    "}\n",
    "\n",
    "# Generate comments for each type\n",
    "generated_comments = {}\n",
    "for comment_type, prompt in prompts.items():\n",
    "    generated_comment = text_generator(prompt, max_length=50, num_return_sequences=1)[0]['generated_text']\n",
    "    generated_comments[comment_type] = generated_comment\n",
    "\n",
    "# Print the generated comments for each type\n",
    "print(\"\\nGenerated Comments:\")\n",
    "for comment_type, comment in generated_comments.items():\n",
    "    print(f\"{comment_type}:\")\n",
    "    print(comment.strip())\n",
    "    print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
