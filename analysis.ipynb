{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(txt):\n",
    "    cleanText = re.sub('http\\S+\\s', ' ', txt)\n",
    "    #http-only select it,http\\S-select http+next one cherecter, http\\S+ -means full address,\\s-next space.\n",
    "    cleanText = re.sub('RT|cc', ' ', cleanText)\n",
    "    #These are often used in tweets and are common in text data from social media.\n",
    "    cleanText = re.sub('#\\S+\\s', ' ', cleanText)\n",
    "    cleanText = re.sub('@\\S+', '  ', cleanText)\n",
    "    cleanText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', cleanText)\n",
    "    #This line removes special characters such as punctuation, excluding whitespaces\n",
    "    cleanText = re.sub(r'[^\\x00-\\x7f]', ' ', cleanText)\n",
    "    #This line removes non-ASCII characters\n",
    "    cleanText = re.sub('\\s+', ' ', cleanText)\n",
    "    #This line substitutes sequences of whitespace characters with a single whitespace character.\n",
    "    #This ensures that multiple consecutive whitespace characters are reduced to just one.\n",
    "    return cleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi how are you Today is the first day of the week \n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hi, how are you? Today is the first day of the week.\"\n",
    "user_input = clean_text(input_text)\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (4.40.2)\n",
      "Requirement already satisfied: filelock in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (2024.5.10)\n",
      "Requirement already satisfied: requests in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in g:\\data science-25\\generative ai\\generation_app\\venv\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi how are you Today is the first day of the week \n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hi, how are you? Today is the first day of the week.\"\n",
    "user_input = clean_text(input_text)\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\DATA SCIENCE-25\\Generative AI\\generation_app\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "g:\\DATA SCIENCE-25\\Generative AI\\generation_app\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) positive 0.9687\n",
      "2) neutral 0.0249\n",
      "3) negative 0.0064\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "#model.save_pretrained(MODEL)\n",
    "text = \"I love you very much\"\n",
    "text = clean_text(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\DATA SCIENCE-25\\Generative AI\\generation_app\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Comments:\n",
      "Friendly:\n",
      "That's fantastic! Hi how are you Today is the first day of the week  of being a vegetarian for your own personal reasons! We've decided to start off by taking a look at three of your favourite ways to feed your animals.\n",
      "\n",
      "Funny:\n",
      "You won't believe it, but Hi how are you Today is the first day of the week  for us, a new start for you. Thank You very much for taking the time to speak with us today. It's a great day,\n",
      "\n",
      "Congratulating:\n",
      "Congratulations on Hi how are you Today is the first day of the week  from all of you.\n",
      "Hi. A short recap with the first day of the week and the start of a month, now that you have all been invited we need\n",
      "\n",
      "Questioning:\n",
      "I'm curious, Hi how are you Today is the first day of the week \"\n",
      "\n",
      "\"Hello and welcome, we live in a small county in south eastern England. I'm on your mobile so don't be rude please come in today\n",
      "\n",
      "Disagreement:\n",
      "Sorry, I have to disagree. Hi how are you Today is the first day of the week  of the concert! As is so frequently the case at the symposium and the workshop the day that is for other people, one of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the text generation pipeline with GPT-2 model\n",
    "text_generator = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\n",
    "\n",
    "# Define functions to generate prompts for different types of comments\n",
    "def generate_friendly_prompt(input_sentence):\n",
    "    return f\"That's fantastic! {input_sentence}\"\n",
    "\n",
    "def generate_funny_prompt(input_sentence):\n",
    "    return f\"You won't believe it, but {input_sentence}\"\n",
    "\n",
    "def generate_congratulating_prompt(input_sentence):\n",
    "    return f\"Congratulations on {input_sentence}\"\n",
    "\n",
    "def generate_questioning_prompt(input_sentence):\n",
    "    return f\"I'm curious, {input_sentence}\"\n",
    "\n",
    "def generate_disagreement_prompt(input_sentence):\n",
    "    return f\"Sorry, I have to disagree. {input_sentence}\"\n",
    "\n",
    "# Get user input sentence\n",
    "#user_sentence = input(\"Enter your sentence: \")\n",
    "\n",
    "# Define prompts for different types of comments\n",
    "prompts = {\n",
    "    \"Friendly\": generate_friendly_prompt(user_input),\n",
    "    \"Funny\": generate_funny_prompt(user_input),\n",
    "    \"Congratulating\": generate_congratulating_prompt(user_input),\n",
    "    \"Questioning\": generate_questioning_prompt(user_input),\n",
    "    \"Disagreement\": generate_disagreement_prompt(user_input)\n",
    "}\n",
    "\n",
    "# Generate comments for each type\n",
    "generated_comments = {}\n",
    "for comment_type, prompt in prompts.items():\n",
    "    generated_comment = text_generator(prompt, max_length=50, num_return_sequences=1)[0]['generated_text']\n",
    "    generated_comments[comment_type] = generated_comment\n",
    "\n",
    "# Print the generated comments for each type\n",
    "print(\"\\nGenerated Comments:\")\n",
    "for comment_type, comment in generated_comments.items():\n",
    "    print(f\"{comment_type}:\")\n",
    "    print(comment.strip())\n",
    "    print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
